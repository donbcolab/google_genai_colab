{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkzzmAPDGY7RB3JP0UVoIo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donbcolab/google_genai_colab/blob/main/gemini_multi_modal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Python Docs Samples](https://github.com/GoogleCloudPlatform/python-docs-samples) Repository\n",
        "- the superhero of the story is Laurent Picard.  His [A Better Way to Use Google Cloud from Colab](https://medium.com/google-colab/a-better-way-to-use-google-cloud-from-colab-bb93f88b5021) Medium article provides a very simple approach for authenticating form Colab to Google Cloud resources.\n",
        "- The Python Docs Samples repository is amazing.  It provides some very concise and to the point examples to test and validate core Google Generative AI models.\n",
        "  - below are some simple ones that I wrapped in a simple gradio application"
      ],
      "metadata": {
        "id": "4QyOREwCzcAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-requisistes\n",
        "\n",
        "- a Google Cloud Project setup with required APIs enabled in **us-central1**\n",
        "- other locations may be available after April 2024\n",
        "- For the current Notebook the key API is\n",
        "  - Vertex AI API (aiplatform.googleapis.com)"
      ],
      "metadata": {
        "id": "WC6CiX1a45rB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Project Setup and Authentication"
      ],
      "metadata": {
        "id": "NsJ_ImpeGJov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "PROJECT_ID = userdata.get('GOOGLE_CLOUD_PROJECT_ID')\n",
        "LOCATION = userdata.get('GOOGLE_CLOUD_LOCATION')"
      ],
      "metadata": {
        "id": "Acig4mxA2OuM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user(project_id=PROJECT_ID)"
      ],
      "metadata": {
        "id": "RiVK2PJB4XYH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Python dependencies"
      ],
      "metadata": {
        "id": "CvJkpZJuGQzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install -U -q google-cloud-aiplatform\n",
        "! pip3 install -U -q 'anthropic[vertex]'\n",
        "! pip install -q gradio"
      ],
      "metadata": {
        "id": "jSigteS_0Vvm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vertex and Gemini App Logic"
      ],
      "metadata": {
        "id": "B4uFdF2jF-F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "import time\n",
        "from vertexai.generative_models import GenerativeModel, ChatSession, Part\n",
        "from vertexai.preview.vision_models import Image, ImageGenerationModel, ImageTextModel\n",
        "from anthropic import AnthropicVertex\n",
        "from vertexai.preview.generative_models import (\n",
        "    grounding,\n",
        "    Tool,\n",
        ")\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "def summarize_audio(audio_file_path):\n",
        "    model = GenerativeModel(\"gemini-1.5-pro-preview-0409\")\n",
        "    prompt = \"\"\"\n",
        "    Please provide a summary for the audio.\n",
        "    Provide chapter titles with timestamps, be concise and short, no need to provide chapter summaries.\n",
        "    Do not make up any information that is not part of the audio and do not be verbose.\n",
        "    \"\"\"\n",
        "    time.sleep(3)\n",
        "    print(audio_file_path)\n",
        "    with open(audio_file_path, \"rb\") as audio_file:\n",
        "        audio_bytes = audio_file.read()\n",
        "    audio = Part.from_data(audio_bytes, mime_type=\"audio/mpeg\")\n",
        "    contents = [audio, prompt]\n",
        "    response = model.generate_content(contents)\n",
        "    return response.text\n",
        "\n",
        "def transcript_audio(audio_file_path):\n",
        "    model = GenerativeModel(\"gemini-1.5-pro-preview-0409\")\n",
        "    prompt = \"\"\"\n",
        "    Transcribe this recording.\n",
        "    If there are multiple speakers capture it in the format of timecode, speaker, caption.\n",
        "    Use speaker A, speaker B, etc. to identify speakers.\n",
        "    \"\"\"\n",
        "    time.sleep(3)\n",
        "    print(audio_file_path)\n",
        "    with open(audio_file_path, \"rb\") as audio_file:\n",
        "        audio_bytes = audio_file.read()\n",
        "    audio = Part.from_data(audio_bytes, mime_type=\"audio/mpeg\")\n",
        "    contents = [audio, prompt]\n",
        "    response = model.generate_content(contents)\n",
        "    return response.text\n",
        "\n",
        "def analyze_video_with_audio(video_file_path):\n",
        "    model = GenerativeModel(\"gemini-1.5-pro-preview-0409\")\n",
        "    prompt = \"\"\"\n",
        "    Provide a description of the video.\n",
        "    The description should also highlight anything important which people say in the video.\n",
        "    \"\"\"\n",
        "    time.sleep(5)\n",
        "    print(video_file_path)\n",
        "    with open(video_file_path, \"rb\") as video_file:\n",
        "        video_bytes = video_file.read()\n",
        "    video = Part.from_data(video_bytes, mime_type=\"video/mp4\")\n",
        "    contents = [video, prompt]\n",
        "    response = model.generate_content(contents)\n",
        "    return response.text\n",
        "\n",
        "def generate_image(prompt):\n",
        "    model = ImageGenerationModel.from_pretrained(\"imagegeneration@006\")\n",
        "\n",
        "    aspect_ratio = \"1:1\"\n",
        "    safety_filter_level = \"block_few\"\n",
        "    person_generation = \"allow_adult\"\n",
        "\n",
        "    generate_response = model.generate_images(\n",
        "        prompt=prompt,\n",
        "        number_of_images=1,\n",
        "        language=\"en\",\n",
        "        aspect_ratio=aspect_ratio,\n",
        "        safety_filter_level=safety_filter_level,\n",
        "        person_generation=person_generation,\n",
        "    )\n",
        "\n",
        "    images = []\n",
        "    for index, result in enumerate(generate_response):\n",
        "        images.append(generate_response[index]._pil_image)\n",
        "    return images[0]\n",
        "\n",
        "def caption_image(input_file):\n",
        "    model = ImageTextModel.from_pretrained(\"imagetext@001\")\n",
        "    time.sleep(5)\n",
        "    print(input_file)\n",
        "    source_img = Image.load_from_file(location=input_file)\n",
        "\n",
        "    captions = model.get_captions(\n",
        "        image=source_img,\n",
        "        language=\"en\",\n",
        "        number_of_results=1,\n",
        "    )\n",
        "\n",
        "    return captions\n",
        "\n",
        "def generate_claude_text(prompt):\n",
        "    client = AnthropicVertex(project_id=PROJECT_ID, region=LOCATION)\n",
        "    result = []\n",
        "\n",
        "    with client.messages.stream(\n",
        "        model=\"claude-3-haiku@20240307\",\n",
        "        max_tokens=1024,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    ) as stream:\n",
        "        for text in stream.text_stream:\n",
        "            result.append(text)\n",
        "\n",
        "    return \"\".join(result)\n",
        "\n",
        "def generate_text_with_grounding(chat_prompt):\n",
        "    model = GenerativeModel(\"gemini-1.5-pro-preview-0409\")\n",
        "    chat = model.start_chat()\n",
        "\n",
        "    def get_chat_response(chat: ChatSession, prompt: str) -> str:\n",
        "        tool = Tool.from_google_search_retrieval(grounding.GoogleSearchRetrieval())\n",
        "\n",
        "        response = chat.send_message(prompt, tools=[tool])\n",
        "        return response.text\n",
        "\n",
        "    prompt = chat_prompt\n",
        "    return get_chat_response(chat, prompt)"
      ],
      "metadata": {
        "id": "Nj21bOSDzCYs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio Web App"
      ],
      "metadata": {
        "id": "bdgvWFARGcKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Gemini Multi Modal Generation and Analysis\")\n",
        "\n",
        "    with gr.Tab(\"Audio Summarization\"):\n",
        "        audio_file_summary = gr.Audio(sources=[\"microphone\", \"upload\"], type=\"filepath\", label=\"Upload Audio\")\n",
        "        summarize_button = gr.Button(\"Summarize Audio\")\n",
        "        summary_output = gr.Textbox(label=\"Audio Summary\")\n",
        "        summarize_button.click(\n",
        "            fn=summarize_audio,\n",
        "            inputs=audio_file_summary,\n",
        "            outputs=summary_output\n",
        "            )\n",
        "\n",
        "    with gr.Tab(\"Audio Transcription\"):\n",
        "        audio_file_transcript = gr.Audio(sources=[\"microphone\", \"upload\"], type=\"filepath\", label=\"Upload Audio\")\n",
        "        transcript_button = gr.Button(\"Transcribe Audio\")\n",
        "        transcript_output = gr.Textbox(label=\"Audio Transcription\")\n",
        "        transcript_button.click(\n",
        "            fn=transcript_audio,\n",
        "            inputs=audio_file_transcript,\n",
        "            outputs=transcript_output\n",
        "            )\n",
        "\n",
        "    with gr.Tab(\"Video Analysis\"):\n",
        "        video_file = gr.Video(label=\"Upload Video\", format=\"mp4\")\n",
        "        analyze_button = gr.Button(\"Analyze Video\")\n",
        "        analysis_output = gr.Textbox(label=\"Video Analysis\")\n",
        "        analyze_button.click(\n",
        "            fn=analyze_video_with_audio,\n",
        "            inputs=video_file,\n",
        "            outputs=analysis_output\n",
        "            )\n",
        "\n",
        "    with gr.Tab(\"Image Generation\"):\n",
        "        image_prompt = gr.Textbox(label=\"Image Prompt\")\n",
        "        generate_button = gr.Button(\"Generate Image\")\n",
        "        image_output = gr.Image(label=\"Generated Images\")\n",
        "        generate_button.click(\n",
        "            fn=generate_image,\n",
        "            inputs=image_prompt,\n",
        "            outputs=image_output\n",
        "            )\n",
        "\n",
        "    with gr.Tab(\"Image Captioning\"):\n",
        "        caption_prompt = gr.Image(label=\"Image\", type=\"filepath\")\n",
        "        caption_button = gr.Button(\"Generate Caption\")\n",
        "        caption_output = gr.Textbox(label=\"Image Caption\")\n",
        "        caption_button.click(\n",
        "            fn=caption_image,\n",
        "            inputs=caption_prompt,\n",
        "            outputs=caption_output\n",
        "            )\n",
        "\n",
        "    with gr.Tab(\"Anthropic Claude\"):\n",
        "        claude_prompt = gr.Textbox(label=\"Prompt\")\n",
        "        claude_button = gr.Button(\"Generate Text\")\n",
        "        claude_output = gr.Textbox(label=\"Generated Text\")\n",
        "        claude_button.click(\n",
        "            fn=generate_claude_text,\n",
        "            inputs=claude_prompt,\n",
        "            outputs=claude_output\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Google Search as a Tool for Grounding\"):\n",
        "        grounding_prompt = gr.Textbox(label=\"Prompt\")\n",
        "        grounding_button = gr.Button(\"Generate Text\")\n",
        "        grounding_output = gr.Textbox(label=\"Generated Text\")\n",
        "        grounding_button.click(\n",
        "            fn=generate_text_with_grounding,\n",
        "            inputs=grounding_prompt,\n",
        "            outputs=grounding_output\n",
        "        )\n",
        "\n",
        "    demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "TccQtsPTzMKC",
        "outputId": "d1257733-afd1-42f1-9875-59395e8b831f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://f0e950f5e861a7127f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f0e950f5e861a7127f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}